{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "869c51a3",
   "metadata": {},
   "source": [
    "# 1. BentoML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36271141",
   "metadata": {},
   "source": [
    "## 1.1 BentoML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e36d17",
   "metadata": {},
   "source": [
    "### 1.1.1 Introduction\n",
    "\n",
    "- FastAPI로 직접 머신러닝 서버 개발\n",
    "  - 1~2개의 모델을 만들 때는 시도하면서 직접 개발 가능\n",
    "- 만약 30개~50개의 모델을 만들어야 한다면?\n",
    "  - 많은 모델을 만들다보니 반복되는 작업이 존재(Config, FastAPI 설정 등)\n",
    "- 이 조차도 더 빠르게 간단하게 하고 싶다. 더 쉽게 만들고 싶다. 추상화 불가능할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffc2263",
   "metadata": {},
   "source": [
    "- 더 쉬운 개발을 위해 본질적인 “Serving”에 특화된 라이브러리를 원하게 됨\n",
    "- 이런 목적의 라이브러리들이 점점 등장하기 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb2725f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.2 Serving Infra\n",
    "\n",
    "- Serving Infra는 모든 회사에서 사용될 수 있는 Base Component\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src='https://drive.google.com/uc?id=1zYHFbOghZSgg-gq9cNLRgQfK5RrecW65' width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae211c5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 많은 라이브러리가 등장하고 있음\n",
    "- 모든 라이브러리는 해결하려고 하는 핵심 문제가 존재\n",
    "- 어떻게 문제를 해결했는지가 다른 라이브러리\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src='https://drive.google.com/uc?id=1zYJIl7s2QDP-xmq5epUwpBxdDZ4RKvVP' width=400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e955136",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.3 BentoML이 해결하는 문제\n",
    "\n",
    "1. Model Serving Infra의 어려움\n",
    "2. Online Serving의 Monitoring 및 Error Handling\n",
    "3. Online Serving 퍼포먼스 튜닝의 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6f863f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1.1.3.1 Model Serving Infra의 어려움\n",
    "\n",
    "- Serving을 위해 다양한 라이브러리, Artifact, Asset 등 사이즈가 큰 파일을 패키징\n",
    "- Cloud Service에 지속적인 배포를 위한 많은 작업이 필요\n",
    "- BentoML은 CLI로 이 문제의 복잡도를 낮춤(CLI 명령어로 모두 진행 가능하도록)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b868f0",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1.1.3.2 Online Serving의 Monitoring 및 Error Handling\n",
    "\n",
    "- Online Serving으로 API 형태로 생성\n",
    "- Error 처리, Logging을 추가로 구현해야 함\n",
    "- BentoML은 Python Logging Module을 사용해 Access Log, Prediction Log를 기본으로 제공\n",
    "- Config를 수정해 Logging도 커스텀할 수 있고, Prometheus 같은 Metric 수집 서버에 전송할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaa6419",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1.1.3.3 Online Serving 퍼포먼스 튜닝의 어려움\n",
    "\n",
    "- BentoML은 [Adaptive Micro Batch](https://docs.bentoml.org/en/latest/guides/micro_batching.html) 방식을 채택해 동시에 많은 요청이 들어와도 높은 처리량을 보여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67edc2c0",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.4 BentoML 소개\n",
    "\n",
    "- Serving에 집중하는 가벼운 Library, BentoML\n",
    "- 2019년부터 개발 시작해서 최근 가파른 성장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6ed6af",
   "metadata": {},
   "source": [
    "- Bento(벤또): 일본의 도시락 요리\n",
    "- Yatai(야타이): 일본식 포장마차\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src='https://drive.google.com/uc?id=1z_i_R9nbxptxIVs1EhY5sCmr2ZlaIISy' width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f949271c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.5 BentoML 특징\n",
    "\n",
    "- 쉬운 사용성\n",
    "- Online / Offline Serving 지원\n",
    "- Tensorflow, PyTorch, Keras, XGBoost 등 Major 프레임워크 지원\n",
    "- Docker, Kubernetes, AWS, Azure 등의 배포 환경 지원 및 가이드 제공\n",
    "- Flask 대비 100배의 처리량\n",
    "- 모델 저장소(Yatai) 웹 대시보드 제공\n",
    "- 데이터 사이언스와 DevOps 사이의 간격을 이어주며 높은 성능의 Serving이 가능하게 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7c3fc3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1.2 BentoML 시작하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2499ae4",
   "metadata": {},
   "source": [
    "### 1.2.1 BentoML 설치\n",
    "\n",
    "- BentoML은 python 3.6 이상 버전을 지원\n",
    "- pyenv 등으로 python version을 3.8으로 설정\n",
    "- 가상 환경 설정(virutalenv or poetry)\n",
    "\n",
    "```\n",
    "pip install bentoml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c48d80",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.2.2 BentoML 사용 Flow\n",
    "\n",
    "- 모델 학습 코드 생성\n",
    "- Prediction Service Class 생성\n",
    "- Prediction Service에 모델 저장 (Pack)\n",
    "- (Local) Serving\n",
    "- Docker Image Build (컨테이너화)\n",
    "- Serving 배포"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1215b02",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1.2.2.1 모델 학습 코드\n",
    "\n",
    "- Iris Classifier 예제\n",
    "\n",
    "```python\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "\n",
    "clf = svm.SVC(gamma='scale')\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "clf.fit(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797e8deb",
   "metadata": {},
   "source": [
    "- (기존에) Serving하기 위해 해야 하는 작업\n",
    "  - FastAPI 웹 서버 생성\n",
    "  - Input, Output 정의\n",
    "  - 의존성 작업 (requirements.txt, Docker 등)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427352ac",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1.2.2.2 Prediction Service Class 생성\n",
    "\n",
    "- **BentoService**를 활용해 Prediction Service Class 생성\n",
    "- 예측할 때 사용하는 API를 위한 Class\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src='https://drive.google.com/uc?id=1z_sMxznJZzdP9HfwN1oRHRIaUaUuNDM4' width=800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25ec51a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "`@env`\n",
    "\n",
    "- 파이썬 패키지, install script 등 서비스에 필요한 의존성을 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bd2963",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "`@artifacts`\n",
    "\n",
    "- 서비스에서 사용할 artifact 정의 (sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff53d1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "`BentoService`\n",
    "\n",
    "- `BentoService`를 상속하면, 해당 서비스를 Yatai(모델 이미지 레지스트리)에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbedaf7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "`@api`\n",
    "\n",
    "- API 생성\n",
    "- Input과 Output을 원하는 형태(Dataframe, Tensor, JSON 등)으로 선택할 수 있음\n",
    "- Doc String으로 Swagger에 들어갈 내용을 추가할 수 있음\n",
    "- `@artifacts`에 사용한 이름을 토대로 `self.artifacts.model`로 접근\n",
    "  - API에 접근할 때 해당 Method 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e98dde",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1.2.2.3 Prediction Service 저장 (Pack)\n",
    "\n",
    "학습한 모델을 Prediction Service에 Pack\n",
    "\n",
    "```python\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "\n",
    "clf = svm.SVC(gamma='scale')\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "clf.fit(X, y)\n",
    "```\n",
    "\n",
    "- `bento_service.py`에 정의한 Prediction Service\n",
    "\n",
    "```python\n",
    "# bento_service.py에서 정의한 IrisClassifier\n",
    "from bento_service import IrisClassifier\n",
    "\n",
    "# IrisClassifier 인스턴스 생성\n",
    "iris_classifier_service = IrisClassifier()\n",
    "```\n",
    "\n",
    "- Model Artifact를 주입\n",
    "- BentoML Bundle\n",
    "  - Prediction Service를 실행할 때 필요한 모든 코드, 구성이 포함된 폴더, 모델 제공을 위한 바이너리\n",
    "\n",
    "```python\n",
    "# Model Artifact를 Pack\n",
    "iris_classifier_service.pack('model', clf)\n",
    "\n",
    "# Model Serving을 위한 서비스를 Disk에 저장\n",
    "saved_path = iris_classifier_service.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0f5107",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- CLI에서 `bento_packer.py` 실행\n",
    "  - \"Saved to ~\" 경로가 보임\n",
    "  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src='https://drive.google.com/uc?id=1za6D-bkIxzBOjSj4uXIlFDwTc2dNhWWe' width=1000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5556f9a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- BentoML에 저장된 Prediction Service 확인\n",
    "\n",
    "```\n",
    "bentoml list\n",
    "```\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src='https://drive.google.com/uc?id=1zcufMSMgbarKiiIOdaVxiD2pxKF_5iJk' width=800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ef4506",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- BentoML에 저장된 Prediction Service 폴더로 이동 후, 파일 확인\n",
    "- `tree` 명령어를 통해 파일 구조 확인\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src='https://drive.google.com/uc?id=1zfHaeEKBnB-qlgb_pGeHIMLqmiBkkX5b' width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a35892",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 우리가 생성한 `bento_service.py` code와 동일\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src='https://drive.google.com/uc?id=1zg0naP3r4DTiholXy5GstdI1MsOoKDmx' width=800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65c90c6",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 우리가 생성하지 않은 `__init__.py`\n",
    "\n",
    "```\n",
    "create_bento_service_cli\n",
    "```\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src='https://drive.google.com/uc?id=1zg2-o5SMMBGxXyeLos9yWpzGdvvwNxxs' width=800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f116a3c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `bentoml.yml`에 모델의 메타정보가 저장됨\n",
    "  - 패키지 환경\n",
    "  - API Input / Output\n",
    "  - Docs 등\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src='https://drive.google.com/uc?id=1zhRUdzkUtXUDY2J_lr7Q53R11psJmR9O' width=800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeec668",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `Dockerfile`도 자동으로 생성되며, 설정을 가지고 설치하는 코드\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src='https://drive.google.com/uc?id=1zhV81kdevHwNN60ffw9wo9SFHwkpQFR3' width=800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96786f70",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 다른 이름의 모델이 Pack 되면 어떻게 되는 지 확인하기 위해 `bento_service.py`의 `IrisClassifier` 클래스를 `IrisClassifier1`로 수정(`bento_packer.py`의 `import` 부분도 수정)한 후 코드 실행\n",
    "\n",
    "```\n",
    "python bento_packer.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ae7762",
   "metadata": {},
   "source": [
    "- `IrisClassifier1`이 새로 생성됨\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src='https://drive.google.com/uc?id=1zkptJJnLoRjjkIhf4sL_IlCV1DJUL8uq' width=800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a603130",
   "metadata": {},
   "source": [
    "- `bentoml list`로 확인\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src='https://drive.google.com/uc?id=1zljga_-if706OhkRQx8Ocldpd6R1ueQT' width=800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdad8f5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1.2.2.4 Serving\n",
    "\n",
    "- 다음 명령어로 serving\n",
    "\n",
    "```\n",
    "bentoml serve IrisClassifier:latest\n",
    "```\n",
    "\n",
    "- 웹서버 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d5a20a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `localhost:5000`로 접근하면 Swagger UI가 보임\n",
    "- 우리가 생성한 `/predict`을 클릭하면 코드에서 정의한 내용을 볼 수 있고, API Test도 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8791701",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- BentoML serve한 터미널에선 로그 발생\n",
    "- 로그는 `~/bentoml/logs`에 저장됨\n",
    "- `prediction.log`를 확인하면 예측 로그를 확인할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a8eb92",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 터미널에서 `curl`로 Request해도 정상적으로 실행됨\n",
    "\n",
    "```\n",
    "curl -i \\\n",
    "  --header \"Content-Type: application/json\" \\\n",
    "  --request POST \\\n",
    "  --data '[[5.1, 3.5, 1.4, 0.2]]' \\\n",
    "  http://localhost:5000/predict\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4420797",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1.2.2.5 Yatai Service 실행\n",
    "\n",
    "```\n",
    "bentoml yatai-service-start\n",
    "```\n",
    "\n",
    "- web UI: `localhost:3000`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0787d2c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1.2.2.6 Docker Image Build\n",
    "\n",
    "```\n",
    "bentoml containerize IrisClassifier:latest -t iris-classifier\n",
    "```\n",
    "\n",
    "- 조금 기다리면 Container Image가 빌드됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ad4623",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- Docker Image로 빌드된 이미지 확인\n",
    "\n",
    "```\n",
    "docker images\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc7e573",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- docker 명령어나 FastAPI를 사용하지 않고 웹 서버를 띄우고, 이미지 빌드 가능\n",
    "  - 예전보다 더 적은 리소스로 개발 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebf0439",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1.3 BentoML Component\n",
    "\n",
    "1. BentoService\n",
    "2. Service Environment\n",
    "3. Model Artifact\n",
    "4. Model Artifact Metadata\n",
    "5. Model Management & Yatai\n",
    "6. API Function and Adapters\n",
    "7. Model Serving\n",
    "8. Labels\n",
    "9. Retrieving BentoServices\n",
    "10. WEB UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27561972",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.1 BentoService\n",
    "\n",
    "- `bentoml.BentoService`\n",
    "  - 예측 서비스를 만들기 위한 베이스 클래스\n",
    "- `@bentoml.artifacts`\n",
    "  - 여러 머신러닝 모델 포함할 수 있음\n",
    "- `@bentoml.api`\n",
    "  - Input/Output 정의\n",
    "  - API 함수 코드에서 `self.artifacts.{ARTIFACT_NAME}`으로 접근할 수 있음\n",
    "- 파이썬 코드와 관련된 종속성 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28763ae1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "```python\n",
    "# bento_svc.py\n",
    "import bentoml\n",
    "from bentoml.adapters import JsonInput\n",
    "from bentoml.frameworks.keras import KerasModelArtifact\n",
    "from bentoml.service.artifacts.common import PickleArtifact\n",
    "\n",
    "@bentoml.env(\n",
    "    pip_packages=['tensorflow', 'scikit-learn', 'pandas'],\n",
    "    docker_base_image=\"bentoml/model-server:0.12.1-py38-gpu\"\n",
    ")\n",
    "@bentoml.artifacts([KerasModelArtifact('model'), PickleArtifact('tokenizer')])\n",
    "class TensorflowService(bentoml.BentoService):\n",
    "    @api(input=JsonInput())\n",
    "    def predict(self, parsed_json):\n",
    "        return self.artifacts.model.predict(input_data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35607db5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "```python\n",
    "# bento_packer.py\n",
    "from bento_svc import TensorflowService\n",
    "\n",
    "# OPTIONAL: to remove tf memory limit on our card\n",
    "config.experimental.set_memory_growth(gpu[0], True)\n",
    "\n",
    "model = load_model()\n",
    "tokenizer = load_tokenizer()\n",
    "\n",
    "bento_svc = TensorflowService()\n",
    "bento_svc.pack('model', model)\n",
    "bento_svc.pack('tokenizer', tokenizer)\n",
    "\n",
    "saved_path = bento_svc.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015ceea4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.2 Service Environment\n",
    "\n",
    "- 파이썬 관련 환경, Docker 등을 설정할 수 있음\n",
    "- `@bentoml.env(infer_pip_packages=True)`\n",
    "  - import를 기반으로 필요한 라이브러리 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba136d8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `requirements_txt_file`을 명시할 수도 있음\n",
    "\n",
    "```python\n",
    "@bentoml.env(\n",
    "    requirements_txt_file=\"./requirements.txt\"\n",
    ")\n",
    "class ExamplePredictionService(bentoml.BentoService):\n",
    "    @bentoml.api(input=DataframeInput(), batch=True)\n",
    "    def predict(self, df):\n",
    "        return self.artifacts.model.predict(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e9938f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `pip_pakcages=[]`를 사용해 버전을 명시할 수 있음\n",
    "\n",
    "```python\n",
    "@bentoml.env(\n",
    "    pip_packages=[\n",
    "        'scikit-learn==0.24.1',\n",
    "        'pandas @https://github.com/pypa/pip/archive/1.3.1.zip'\n",
    "    ]\n",
    ")\n",
    "class ExamplePredictionService(bentoml.BentoService):\n",
    "    @bentoml.api(input=DataframeInput(), batch=True)\n",
    "    def predict(self, df):\n",
    "        return self.artifacts.model.predict(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41735d24",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `docker_base_image`를 사용해 Base Image를 지정할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf84c31",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `setup_sh`를 지정해 Docker Build 과정을 커스텀할 수 있음\n",
    "\n",
    "```python\n",
    "@bentoml.env(\n",
    "    infer_pip_packages=True,\n",
    "    setup_sh=\"./my_init_script.sh\"\n",
    ")\n",
    "class ExamplePredictionService(bentoml.BentoService):\n",
    "    ...\n",
    "    \n",
    "@bentoml.env(\n",
    "    infer_pip_pakcages=True,\n",
    "    setup_sh=\"\"\"\\\n",
    "#!/bin/bash\n",
    "set -e\n",
    "\n",
    "apt-get install --no-install-recommends nvidia-driver-430\n",
    "...\n",
    "\"\"\"\n",
    ")\n",
    "class ExamplePredictionService(bentoml.BentoService):\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cb0f62",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `@bentoml.ver`를 사용해 버전 지정할 수 있음\n",
    "\n",
    "```python\n",
    "from bentoml import ver, artifacts\n",
    "from bentoml.service.artifacts.common import PickleArtifact\n",
    "\n",
    "@ver(major=1, minor=4)\n",
    "@artifacts([PickleArtifact('model')])\n",
    "class MyMLService(BentoService):\n",
    "    pass\n",
    "\n",
    "svc = MyMLService()\n",
    "svc.pack(\"model\", trained_classifier)\n",
    "svc.set_version(\"2019-08.iteration20\")\n",
    "svc.save()\n",
    "\n",
    "# The final produced BentoService bundle will have version:\n",
    "# \"1.4.2019-08.iteration20\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9613962",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.3 Model Artifact\n",
    "\n",
    "- `@bentoml.artifacts`\n",
    "  - 사용자가 만든 모델을 저장해 pretrain model을 읽어 Serialization, Deserialization\n",
    "- 여러 모델을 같이 저장할 수 있음\n",
    "- A 모델의 예측 결과를 B 모델의 Input으로 사용할 경우\n",
    "- 보통 하나의 서비스 당 하나의 모델을 권장\n",
    "\n",
    "```python\n",
    "import bentoml\n",
    "from bentoml.adapters import DataframeInput\n",
    "from bentoml.frameworks.sklearn import SklearnModelArtifact\n",
    "from bentoml.frameworks.xgboost import XgboostModelArtifact\n",
    "\n",
    "@bentoml.env(infer_pip_packages=True)\n",
    "@bentoml.artifacts([\n",
    "    SklearnModelArtifact(\"model_a\"),\n",
    "    XgboostModelArtifact(\"model_b\")\n",
    "])\n",
    "class MyPredictionService(bentoml.BentoService):\n",
    "    \n",
    "    @bentoml.api(input=DataframeInput(), batch=True)\n",
    "    def predict(self, df):\n",
    "        # assume the output of model_a will be the input of model_b in this example\n",
    "        df = self.artifacts.model_a.predict(df)\n",
    "        \n",
    "        return self.artifacts.model_b.predict(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ada5a39",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "```python\n",
    "svc = MyPredictionService()\n",
    "svc.pack(\"model_a\", my_sklearn_model_object)\n",
    "svc.pack(\"model_b\", my_xgboost_model_object)\n",
    "svc.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c81159",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 다음 라이브러리의 Artifact를 지원\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src='https://drive.google.com/uc?id=1znkBehudZuOGrBFR-adxmD7ddk7FYedq' width=300/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518fc1a7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.4 Model Artifact Metadata\n",
    "\n",
    "- 해당 모델의 Metadata(Metric - Accuracy, 사용한 데이터셋, 생성한 사람, static 정보 등)\n",
    "- Pack에서 `metadata` 인자에 넘겨주면 메타데이터 저장\n",
    "- 메타데이터는 Immutable\n",
    "\n",
    "```python\n",
    "svc = MyPredictionService()\n",
    "svc.pack(\n",
    "    \"model_a\",\n",
    "    my_sklearn_model_object,\n",
    "    metadata={\n",
    "        \"precision_score\": 0.876,\n",
    "        \"created_by\": \"joe\"\n",
    "    }\n",
    ")\n",
    "svc.pack(\n",
    "    \"model_b\",\n",
    "    my_xgboost_model_object,\n",
    "    metadata={\n",
    "        \"precision_score\": 0.792,\n",
    "        \"mean_absolute_error\": 0.88\n",
    "    }\n",
    ")\n",
    "svc.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9524f93",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Metadata 접근 방법 (1) - CLI\n",
    "\n",
    "```\n",
    "bentoml get model:version\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6588d41",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Metadata 접근 방법 (2) - REST API\n",
    "\n",
    "- `bentoml serve` 한 후, `/metadata`로 접근"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db5c925",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Metadata 접근 방법 (3) - Python\n",
    "\n",
    "```python\n",
    "from bentoml import load\n",
    "svc = load(\"path_to_bento_service\")\n",
    "print(svc.artifacts['model'].metadata)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de12db6",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.5 Model Management & Yatai\n",
    "\n",
    "- BentoService의 `save` 함수는 BentoML Bundle을 `~/bentoml/repository/{서비스 이름}/{서비스 버전}`에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99221509",
   "metadata": {},
   "source": [
    "- 모델 리스트 확인\n",
    "\n",
    "```\n",
    "bentoml list\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e6d19b",
   "metadata": {},
   "source": [
    "- 특정 모델 정보 가져오기\n",
    "\n",
    "```\n",
    "bentoml get IrisClassifier\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2dccd9",
   "metadata": {},
   "source": [
    "- YataiService\n",
    "  - 모델 저장 및 배포를 처리하는 컴포넌트\n",
    "\n",
    "```\n",
    "bentoml yatai-service-start\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f0f8db",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.6 API Function and Adapters\n",
    "\n",
    "- BentoService API는 클라이언트가 예측 서비스에 접근하기 위한 End Point 생성\n",
    "- Adapter는 Input / Output을 추상화해서 중간 부분을 연결하는 Layer\n",
    "  - ex) csv 파일 형식으로 예측을 요청할 경우, `DataframeInput`을 사용하고 있으면 내부적으로 `pandas.DataFrame` 객체로 변환하고 API 함수에 전달함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1087c10",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `@bentoml.api`를 사용해 입력 받은 데이터를 `InputAdapter` 인스턴스에 넘김\n",
    "- 데이터 처리하는 함수도 작성할 수 있음\n",
    "\n",
    "```python\n",
    "from my_lib import preprocessing, postprocessing, fetch_user_profile_from_database\n",
    "\n",
    "class ExamplePredictionService(bentoml.BentoService):\n",
    "    \n",
    "    @bentoml.api(input=DataframeInput(), batch=True)\n",
    "    def predict(self, df):\n",
    "        user_profile_column = fetch_user_profile_from_database(df['user_id'])\n",
    "        df['user_prifile'] = user_profile_column\n",
    "        model_input = preprocessing(df)\n",
    "        model_output = self.artifacts.model.predict(model_input)\n",
    "        return postprocessing(model_output)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ed57e7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- Input 데이터가 이상할 경우 오류 코드를 반환할 수 있음\n",
    "\n",
    "```python\n",
    "from typing import List\n",
    "from bentoml import env, artifacts, api, BentoService\n",
    "from bentoml.adapters import JsonInput\n",
    "from bentoml.types import JsonSerializable, InferenceTask # type annotations are optional\n",
    "\n",
    "@env(infer_pip_packages=True)\n",
    "@artifacts([SklearnModelArtifact('classifier')])\n",
    "class MyPredictionService(BentoService):\n",
    "    \n",
    "    @api(input=JsonInput(), batch=True)\n",
    "    def predict_batch(self, parased_json_list: List[JsonSerializable], tasks: List[InferenceTask]):\n",
    "        model_input = []\n",
    "        for json, task in zip(parsed_json_list, tasks):\n",
    "            if \"text\" in json:\n",
    "                model_input.append(json[\"text\"])\n",
    "            else:\n",
    "                task.discard(http_status=400, err_msg=\"input json must contain 'text' field\")\n",
    "                \n",
    "        results = self.artifacts.classifier(model_input)\n",
    "        \n",
    "        return results\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f343e391",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 세밀하게 Response를 정의할 수 있음\n",
    "\n",
    "```python\n",
    "import bentoml\n",
    "from bentoml.types import JsonSerializable, InferenceTask, InferenceError, InferenceResult\n",
    "\n",
    "class MyService(bentoml.BentoService):\n",
    "    \n",
    "    @bentoml.api(input=JsonInput(), batch=True)\n",
    "    def predict(self, parsed_json: JsonSerializable, task: InferenceTask) -> InferenceResult:\n",
    "        if task.http_headers['Accept'] == \"application/json\":\n",
    "            predictions = self.artifact.model.predict([parsed_json])\n",
    "            return InferenceResult(\n",
    "                data=predictions[0],\n",
    "                http_status=200,\n",
    "                http_headers={\"Content-Type\": \"application/json\"}\n",
    "            )\n",
    "        else:\n",
    "            return InferenceError(err_msg=\"application/json output only\", http_status=400)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66822853",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `BentoService`가 여러 API를 포함할 수 있음\n",
    "\n",
    "```python\n",
    "from my_lib import process_custom_json_format\n",
    "\n",
    "class ExamplePredictionService(bentoml.BentoService):\n",
    "    \n",
    "    @bentoml.api(input=DataframeInput(), batch=True)\n",
    "    def predict(self, df: pandas.DataFrame):\n",
    "        return self.artifacts.model.predict(df)\n",
    "    \n",
    "    @bentoml.apip(input=JsonInput(), batch=True)\n",
    "    def predict_json(self, json_arr):\n",
    "        df = process_custom_json_format(json_arr)\n",
    "        return self.artifacts.model.predict(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801254e4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.7 Model Serving\n",
    "\n",
    "- `BentoService`가 bento로 저장되면, 여러 방법으로 배포할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376f9817",
   "metadata": {},
   "source": [
    "1. Online Serving\n",
    "  - 클라이언트가 REST API Endpoint로 근 실시간으로 예측 요청\n",
    "2. Offline Batch Serving\n",
    "  - 예측을 계산한 후, Storage에 저장\n",
    "3. Edge Serving\n",
    "  - 모바일, IoT Device에 배포"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da65b97",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.8 Retrieving BentoServices\n",
    "\n",
    "- 학습한 모델을 저장한 후, Artifact bundle을 찾을 수 있음\n",
    "- `--target_dir flag`를 사용\n",
    "\n",
    "```\n",
    "bentoml retrieve ModelServe --target_dir=~/bentoml_bundle/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbca1ff",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.9 WEB UI\n",
    "\n",
    "- `@bentoml.web_static_content`를 사용하면 웹 프론트엔드에 추가할 수 있음\n",
    "- 참고 링크: [https://github.com/bentoml/gallery/tree/master/scikit-learn/iris-classifier](https://github.com/bentoml/gallery/tree/master/scikit-learn/iris-classifier)\n",
    "\n",
    "```python\n",
    "%%writefile iris_classifier.py\n",
    "from bentoml import env, artifacts, api, BentoService, web_static_content\n",
    "from bentoml.adapters import DataframeInput\n",
    "from bentoml.artifact import SklearnModelArtifact\n",
    "\n",
    "@env(auto_pip_dependencies=True)\n",
    "@artifacts([SklearnModelArtifact('model')])\n",
    "@web_static_content('./static')\n",
    "class IrisClassifier(BentoService):\n",
    "    \n",
    "    @api(input=DataframeInput(), batch=True)\n",
    "    def test(self, df):\n",
    "        # Optional pre-processing, post-processing code goes here\n",
    "        return self.artifacts.model.predict(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb6614",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1.4 BentoML으로 Serving 코드 리팩토링하기\n",
    "\n",
    "- [https://github.com/zzsza/Boostcamp-AI-Tech-Product-Serving/tree/main/part4/01-bentoml/app](https://github.com/zzsza/Boostcamp-AI-Tech-Product-Serving/tree/main/part4/01-bentoml/app)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d3f5b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.4.1 BentoService 정의하기\n",
    "\n",
    "- import된 모듈로 패키지 의존성을 추론해 추가\n",
    "- 마스크 분류 모델에서 사용한 `PytorchModelArtifact` 추가\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src='https://drive.google.com/uc?id=1znzlgc5oylJAzsQSFuwRY7Bt8GU5k5yu' width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ba3ccf",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- image input을 사용해서 업로드된 이미지로부터 `imageio.Array`를 함수 인자로 주입\n",
    "- output은 json으로 클라이언트에게 제공\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src='https://drive.google.com/uc?id=1zps6baIbVhC0fXVjx7iGAoixVf52bzSo' width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e7cb69",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 사용하기 전에 [공식 Document](https://docs.bentoml.org/en/latest/api/adapters.html)를 보는 습관!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110566e7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- FastAPI에서 썼던 코드와 거의 동일\n",
    "- `@api` 데코레이터가 붙은 Method 말고도 `self.transform` 같은 추가 Method도 사용 가능\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src='https://drive.google.com/uc?id=1zqicCG6Dnp1JBtBkKXH04OMH400x5S1i' width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a0d46a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.4.2 Model Pack\n",
    "\n",
    "- Service를 초기화하고 Model Load\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src='https://drive.google.com/uc?id=1zsLP6sI9XzxCZBZsh4OGH72wRVBbsCFT' width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cc72bb",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 서비스를 Pack하고 Yatai에 저장\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src='https://drive.google.com/uc?id=1zsdcJeB5WS9-NlNP4NXQxezZtcZSgQLp' width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1326224",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `http://localhost:%port`로 접속하면 Swagger를 확인할 수 있음\n",
    "- Test Execute하면 정상적으로 값이 Return!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7009a37",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 기존 Requests하는 URL을 5001로 변경하면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edca65b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
